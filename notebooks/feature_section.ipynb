{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Sat Nov 25 10:36:43 2023\\n\\n@author: Rebecca Tobin\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Sat Nov 25 10:36:43 2023\n",
    "\n",
    "@author: Rebecca Tobin\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1 = pd.read_csv('../data/raw/R1_train.csv') \n",
    "R1 = (np.array(R1))\n",
    "R2 = pd.read_csv('../data/raw/R2_train.csv') \n",
    "R2 = (np.array(R2))\n",
    "R3 = pd.read_csv('../data/raw/R3_train.csv') \n",
    "R3 = (np.array(R3))\n",
    "R4 = pd.read_csv('../data/raw/R4_train.csv') \n",
    "R4 = (np.array(R4))\n",
    "R5 = pd.read_csv('../data/raw/R5_train.csv') \n",
    "R5 = (np.array(R5))\n",
    "R6 = pd.read_csv('../data/raw/R6_train.csv') \n",
    "R6 = (np.array(R6))\n",
    "\n",
    "Rfiles = [R1,R2,R3,R4,R5,R6]\n",
    "\n",
    "y = pd.read_csv('../data/raw/labels_train.csv') \n",
    "y = (np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique rows of y are there?\n",
    "\n",
    "# # Data frame of the unique rows\n",
    "# unique_rows_y = y.drop_duplicates()\n",
    "# # Adding a unique identifier to each unique row\n",
    "# unique_rows_y[\"identifier\"] = np.arange(len(unique_rows_y))\n",
    "\n",
    "# # finding the unique identifier for each row in y\n",
    "# y_wid = pd.merge(y, unique_rows_y, how='left', \n",
    "#                  on=['0','1','2','3','4','5','6','7','8','9','10','11','12','13',\n",
    "#                      '14','15','16','17','18'])\n",
    "\n",
    "# # Number of instances that each unique row occurs\n",
    "# unique_rows_y_counts = pd.DataFrame((y_wid['identifier']).value_counts())\n",
    "# plt.figure()\n",
    "# plt.hist(unique_rows_y_counts['count'], bins = 30, log = True)\n",
    "# plt.ylabel('Count')\n",
    "# plt.xlabel('Number of repetitions of a unique set of labels')\n",
    "# plt.show()\n",
    "\n",
    "# # Number of rows with a certain number of repetitions\n",
    "# num_repetitions = pd.DataFrame((unique_rows_y_counts['count']).value_counts())\n",
    "# print(\"Top 10 most common number of repetitions of a unique set of labels\")\n",
    "# print(num_repetitions.loc[1:11])\n",
    "\n",
    "# del(unique_rows_y,y_wid,unique_rows_y_counts,num_repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_mass_split(y, folds=10):\n",
    "    # add shuffle?\n",
    "    y = np.array(y)\n",
    "    obs, classes = y.shape\n",
    "    dist = y.sum(axis=0).astype('float')\n",
    "    dist /= dist.sum()\n",
    "    dist = np.array(dist)\n",
    "    index_list = []\n",
    "    fold_dist = np.zeros((folds, classes), dtype='float')\n",
    "    for _ in range(folds):\n",
    "        index_list.append([])\n",
    "    for i in range(obs):\n",
    "        # add one obs to each fold so that each fold has one obs\n",
    "        if i < folds:\n",
    "            target_fold = i\n",
    "        # once each fold has one observation, do this\n",
    "        else:\n",
    "            normed_folds = fold_dist.T / fold_dist.sum(axis=1)\n",
    "            # how off is the ditribution of each fold from the desired distribution\n",
    "            how_off = normed_folds.T - dist\n",
    "            # find the fold that minimizing the dot product to decide where \n",
    "            # to put the ith observation\n",
    "            target_fold = np.argmin(np.dot((y[i] - .5).reshape(1, -1), how_off.T))\n",
    "        # keep track of how adding y[i] to the fold changes the distribution\n",
    "        fold_dist[target_fold] += y[i]\n",
    "        # add y[i] to the index list for the chosen fold\n",
    "        index_list[target_fold].append(i)\n",
    "    \n",
    "    return fold_dist, dist, index_list\n",
    "\n",
    "fold_dist, dist, index_list = proba_mass_split(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normed_folds = fold_dist.T/fold_dist.sum(axis=1)\n",
    "# class_list = (np.arange(19)).astype(str)\n",
    "\n",
    "# data = {'All data': dist,\n",
    "#         'Fold 1': normed_folds[:,0],\n",
    "#         'Fold 2': normed_folds[:,1],\n",
    "#         'Fold 3': normed_folds[:,2]}\n",
    "\n",
    "# data = pd.DataFrame(data, columns=['All data', 'Fold 1', 'Fold 2', 'Fold 3'], \n",
    "#                     index = class_list)\n",
    "\n",
    "# # Multiple bar chart\n",
    "# data.plot.bar(xlabel = 'Class', ylabel = 'Frequency')\n",
    "\n",
    "# for j in range(len(index_list)):\n",
    "#     len_index_list = len(index_list[j])\n",
    "#     print(f\"Number of obs. in fold {j+1}: {len_index_list}\")\n",
    "\n",
    "# # Code modified from \n",
    "# # https://stats.stackexchange.com/questions/65828/how-to-use-scikit-learns-cross-validation-functions-on-multi-label-classifiers\n",
    "# # To to self: remember to cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mutakabbir/miniconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rfile 1, fold 1, f1_score: 0.6827157909427116\n"
     ]
    }
   ],
   "source": [
    "f1_matrix = np.zeros((6,10))\n",
    "# For each R file (each subset of features)\n",
    "\n",
    "for k in range(len(Rfiles)): # \n",
    "    X = Rfiles[k]\n",
    "    # For each fold\n",
    "    for i in range(10):\n",
    "        train_index = []\n",
    "        for j in range(10):\n",
    "            if j != i:\n",
    "                train_index = train_index + index_list[j]\n",
    "        test_index = index_list[i]\n",
    "        \n",
    "        y_train = y[train_index,:]\n",
    "        X_train = X[train_index,:]\n",
    "        y_test = y[test_index,:]\n",
    "        X_test = X[test_index,:]\n",
    "    \n",
    "        # didn't let me have no hidden layers\n",
    "        clf = MLPClassifier(solver = 'adam', activation='logistic', max_iter=50,\n",
    "                            hidden_layer_sizes=(np.shape(X)[1]))\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        f1_score_output = f1_score(y_test, y_pred, average = 'micro')\n",
    "        print(f\"Rfile {k+1}, fold {i+1}, f1_score: {f1_score_output}\")\n",
    "        f1_matrix[k,i] = f1_score_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mutakabbir/Projects/SYSC 5405/SYSC5405-pattern-analysis-and-experiment-design/notebooks/feature_section.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mutakabbir/Projects/SYSC%205405/SYSC5405-pattern-analysis-and-experiment-design/notebooks/feature_section.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m CV_score \u001b[39m=\u001b[39m cross_val_score(clf, X_train, y_train, cv \u001b[39m=\u001b[39m CV)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mutakabbir/Projects/SYSC%205405/SYSC5405-pattern-analysis-and-experiment-design/notebooks/feature_section.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m CV_scores\u001b[39m.\u001b[39mappend(CV_score)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mutakabbir/Projects/SYSC%205405/SYSC5405-pattern-analysis-and-experiment-design/notebooks/feature_section.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mean_CV_scores\u001b[39m.\u001b[39mappend(CV_score\u001b[39m.\u001b[39mmean())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "# CV_score = cross_val_score(clf, X_train, y_train, cv = CV)\n",
    "# CV_scores.append(CV_score)\n",
    "# mean_CV_scores.append(CV_score.mean())\n",
    "# std_CV_scores.append(CV_score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
