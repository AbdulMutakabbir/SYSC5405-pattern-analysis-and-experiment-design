{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from pandas import DataFrame, read_csv\n",
    "from torch import device, cuda, from_numpy\n",
    "from torch.nn import Module, Linear, Sigmoid, BCELoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deice: cuda\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "BATCH_SIZE = 2048*16\n",
    "RANDOM_STATE = 1\n",
    "WORKERS = 16\n",
    "TRAIN_SPLIT = 0.75\n",
    "\n",
    "device = device(\"cuda\" if cuda.is_available() else \"cpu\")\n",
    "print(f\"Deice: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "RAW_DATA_DIR = f\"{DATA_DIR}/raw\"\n",
    "\n",
    "MIN_R = 1\n",
    "MAX_R = 6\n",
    "\n",
    "Rs = list(range(MIN_R,MAX_R+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lables_loc = f\"{RAW_DATA_DIR}/labels_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_train_set(r:int, data_dir:str=RAW_DATA_DIR):\n",
    "    return f\"{data_dir}/R{r}_train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = read_csv(get_lables_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load R's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dfs = {r:read_csv(get_r_train_set(r=r)) for r in Rs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelDatasetHolder():\n",
    "    def __init__(self, label_column:str, labels_df:DataFrame, r_id:int, r_dfs:DataFrame):\n",
    "\n",
    "        class LabelDataset(Dataset):\n",
    "            def __init__(self, features, labels):\n",
    "                self.features = features#.to(device)\n",
    "                self.labels = labels#.to(device)\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.labels)\n",
    "            \n",
    "            def __getitem__(self, index):\n",
    "                return self.features[index], self.labels[index]\n",
    "    \n",
    "        print(f\"Dataset Creating started.\")\n",
    "\n",
    "        # inti meta data\n",
    "        self.r_id = r_id\n",
    "        self.label_column = label_column\n",
    "        self.feature_count = len(r_dfs[self.r_id].columns)\n",
    "        print(f\"Initialization of Meta data is complete.\")\n",
    "\n",
    "        # init dataset\n",
    "        self.features = from_numpy(r_dfs[self.r_id].to_numpy()).float()\n",
    "        self.labels = from_numpy(labels_df[[self.label_column]].to_numpy()).float()\n",
    "        print(f\"{self.feature_count} Features and Label Column {self.label_column} was initialized!!!\")\n",
    "\n",
    "        # create a test trian split of the dataset\n",
    "        x_trian, x_test, y_train, y_test = train_test_split(\n",
    "            self.features, \n",
    "            self.labels, \n",
    "            stratify=self.labels,\n",
    "            random_state=RANDOM_STATE, \n",
    "            train_size=TRAIN_SPLIT, \n",
    "            shuffle=True, \n",
    "        )\n",
    "        self.train_dataset = LabelDataset(features=x_trian, labels=y_train)\n",
    "        self.test_dataset = LabelDataset(features=x_test, labels=y_test)\n",
    "        print(f\"Created test and train split.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Creating started.\n",
      "Initialization of Meta data is complete.\n",
      "768 Features and Label Column 0 was initialized!!!\n",
      "Created test and train split.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test creation of dataset\n",
    "dataset = LabelDatasetHolder(\n",
    "    label_column=labels_df.columns[0], \n",
    "    labels_df=labels_df,\n",
    "    r_id=Rs[0],\n",
    "    r_dfs=r_dfs\n",
    ")\n",
    "\n",
    "train_dataset = dataset.train_dataset\n",
    "test_dataset = dataset.test_dataset\n",
    "\n",
    "train_dataset[:3][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelPredictor(Module):\n",
    "    def __init__(self, feature_count):\n",
    "        super(LabelPredictor, self).__init__()\n",
    "        self.layer = Linear(in_features=feature_count, out_features=1)\n",
    "        self.out_activation = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = self.out_activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing creation of Model\n",
    "model = LabelPredictor(feature_count=dataset.feature_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Creating started.\n",
      "Initialization of Meta data is complete.\n",
      "768 Features and Label Column 0 was initialized!!!\n",
      "Created test and train split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R: 1, Label:0:   0%|          | 0/1000 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R: 1, Label:0: 100%|██████████| 1000/1000 [07:27<00:00,  2.24epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Creating started.\n",
      "Initialization of Meta data is complete.\n",
      "768 Features and Label Column 0 was initialized!!!\n",
      "Created test and train split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R: 2, Label:0: 100%|██████████| 1000/1000 [07:28<00:00,  2.23epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Creating started.\n",
      "Initialization of Meta data is complete.\n",
      "768 Features and Label Column 0 was initialized!!!\n",
      "Created test and train split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R: 3, Label:0: 100%|██████████| 1000/1000 [07:33<00:00,  2.21epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Creating started.\n",
      "Initialization of Meta data is complete.\n",
      "1024 Features and Label Column 0 was initialized!!!\n",
      "Created test and train split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R: 4, Label:0: 100%|██████████| 1000/1000 [07:52<00:00,  2.11epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Creating started.\n",
      "Initialization of Meta data is complete.\n",
      "1024 Features and Label Column 0 was initialized!!!\n",
      "Created test and train split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R: 5, Label:0: 100%|██████████| 1000/1000 [07:53<00:00,  2.11epoch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Creating started.\n",
      "Initialization of Meta data is complete.\n",
      "1024 Features and Label Column 0 was initialized!!!\n",
      "Created test and train split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R: 6, Label:0:  50%|████▉     | 496/1000 [03:54<04:01,  2.08epoch/s]"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "for label in labels_df.columns:\n",
    "    for r in Rs:\n",
    "        # build the dataset\n",
    "        dataset = LabelDatasetHolder(\n",
    "            label_column=label, \n",
    "            labels_df=labels_df,\n",
    "            r_id=r,\n",
    "            r_dfs=r_dfs\n",
    "        )\n",
    "        train_dataset = dataset.train_dataset\n",
    "        test_dataset = dataset.test_dataset\n",
    "        train_dataloader = DataLoader(train_dataset, num_workers=WORKERS, pin_memory=True, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_dataloader = DataLoader(test_dataset, num_workers=WORKERS, pin_memory=True, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        # create model\n",
    "        model = LabelPredictor(feature_count=dataset.feature_count)\n",
    "        model#.to(device)\n",
    "\n",
    "        # init loss and optimizer\n",
    "        criterion = BCELoss()  # Binary Cross Entropy Loss since it's a multilabel problem\n",
    "        optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "        # start training\n",
    "        for epoch in tqdm(range(EPOCHS), desc=f\"R:{r:2}, Label:{label}\", unit='epoch',):\n",
    "            total_loss = 0.0\n",
    "            for x, y in train_dataloader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                op = model(x)\n",
    "\n",
    "                loss = criterion(op, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            average_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        models[(r, label)] = model\n",
    "            \n",
    "        del model\n",
    "        del dataset\n",
    "        del train_dataset\n",
    "        del test_dataset\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
